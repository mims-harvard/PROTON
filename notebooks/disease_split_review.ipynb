{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLM Review of Disease-Centric Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from openai import AzureOpenAI\n",
        "from tqdm import tqdm\n",
        "\n",
        "from src.config import conf\n",
        "\n",
        "_logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read in disease splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "nodes = pd.read_csv(conf.paths.kg.nodes_path, dtype={\"node_index\": int}, low_memory=False)\n",
        "edges = pd.read_csv(\n",
        "    conf.paths.kg.edges_path, dtype={\"edge_index\": int, \"x_index\": int, \"y_index\": int}, low_memory=False\n",
        ")\n",
        "disease_splits = pd.read_csv(conf.paths.splits_dir / \"disease_splits.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set up the GPT-4 client."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = AzureOpenAI(\n",
        "    azure_endpoint=conf.AZURE_OPENAI_ENDPOINT,\n",
        "    api_key=conf.AZURE_OPENAI_API_KEY,\n",
        "    api_version=\"2024-05-01-preview\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use GPT-4 to evaluate disease splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPT-4o evaluation of disease splits:   0%|                                                                                                                            | 0/1406 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "gpt_ranks = []\n",
        "tokens_used = []\n",
        "\n",
        "for _i, row in tqdm(disease_splits.iterrows(), desc=\"GPT-4o evaluation of disease splits\", total=len(disease_splits)):\n",
        "    # Construct message\n",
        "    split_disease = nodes[nodes[\"node_index\"] == row[\"disease_split_index\"]][\"node_name\"].values[0]\n",
        "    candidate_disease = row[\"node_name\"]\n",
        "    split_disease = split_disease.replace(\"(disease)\", \"\").strip()\n",
        "    candidate_disease = candidate_disease.replace(\"(disease)\", \"\").strip()\n",
        "\n",
        "    message = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a helpful biomedical expert with an understanding of disease mechanisms, treatment options for every disease, and deep clinical knowledge of disease symptoms, phenotypes, genotypes, and drug treatments.\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Rank on a scale from 1 to 5 how closely related {split_disease} and {candidate_disease} are. 1 is not related at all, 4 is that that they are closely related (e.g., a drug that treats {split_disease} could also treat {candidate_disease}), 5 is that they are the same disease or subtypes of the same disease. Respond with a number from 1-5 only, no other text.\",\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    # Submit query for inference\n",
        "    # Approx. 82 tokens per completion\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-1120\",\n",
        "        messages=message,\n",
        "        temperature=0.5,\n",
        "        max_tokens=1,\n",
        "    )\n",
        "\n",
        "    # Append to list\n",
        "    gpt_ranks.append(response.choices[0].message.content)\n",
        "    tokens_used.append(response.usage.total_tokens)\n",
        "\n",
        "# Add to disease splits\n",
        "disease_splits[\"gpt_rank\"] = gpt_ranks\n",
        "disease_splits[\"tokens_used\"] = tokens_used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1    561\n",
            "5    387\n",
            "4    163\n",
            "2    160\n",
            "3    135\n",
            "Name: gpt_rank, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "disease_splits[\"gpt_rank\"] = disease_splits[\"gpt_rank\"].astype(int)\n",
        "_logger.info(disease_splits[\"gpt_rank\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set self comparisons to `Yes`. Set all non-`Yes`/`No` comparisons to `No`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No     721\n",
            "Yes    685\n",
            "Name: gpt_eval, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Construct gpt_eval as 'Yes' if gpt_rank >= 3, 'No' if gpt_rank < 3\n",
        "disease_splits[\"gpt_eval\"] = np.where(disease_splits[\"gpt_rank\"] >= 3, \"Yes\", \"No\")\n",
        "\n",
        "# Set self comparisons to 'Yes'\n",
        "disease_splits.loc[disease_splits[\"node_index\"] == disease_splits[\"disease_split_index\"], \"gpt_eval\"] = \"Yes\"\n",
        "_logger.info(disease_splits[\"gpt_eval\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute total tokens used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total tokens used: 203471\n"
          ]
        }
      ],
      "source": [
        "_logger.info(\"Total tokens used:\", sum(disease_splits[\"tokens_used\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save file to CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "disease_splits.to_csv(conf.paths.splits_dir / \"disease_splits_GPT.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Disease Splits\n",
        "\n",
        "Save each split to its own file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_dir = conf.paths.splits_dir / \"split_edges_GPT\"\n",
        "if os.path.isdir(split_dir):\n",
        "    shutil.rmtree(split_dir)\n",
        "os.mkdir(split_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get drug_disease_edges\n",
        "drug_disease_edges = edges[(edges[\"x_type\"] == \"disease\") & (edges[\"y_type\"] == \"drug\")]\n",
        "\n",
        "# Filter to GPT-4 evaluations of 'Yes'\n",
        "disease_splits_filtered = disease_splits[disease_splits[\"gpt_eval\"] == \"Yes\"]\n",
        "disease_splits_grouped = disease_splits_filtered.groupby(\"disease_split_index\")\n",
        "edge_count = {}\n",
        "\n",
        "for disease_split, disease_split_df in tqdm(disease_splits_grouped, desc=\"Save splits\"):\n",
        "    \n",
        "    # Get indication edges\n",
        "    disease_split_edges = drug_disease_edges[drug_disease_edges[\"x_index\"].isin(disease_split_df[\"node_index\"])]\n",
        "    disease_split_edges = disease_split_edges.reset_index(drop=True)\n",
        "\n",
        "    # If some edges exist\n",
        "    if len(disease_split_edges) > 0:\n",
        "\n",
        "        # Save to CSV\n",
        "        disease_split_edges.to_csv(split_dir / f\"{disease_split}.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "        edge_count[disease_split] = len(disease_split_edges)\n",
        "\n",
        "    else:\n",
        "\n",
        "        # Drop from disease_splits\n",
        "        disease_splits_filtered = disease_splits_filtered[\n",
        "            ~disease_splits_filtered[\"disease_split_index\"].isin(disease_split_df[\"node_index\"])\n",
        "        ]\n",
        "        tqdm.write(f\"Removed split {disease_split} ({disease_split_df['disease_split'].values[0]}) as it has no edges.\")\n",
        "\n",
        "# Save all disease splits\n",
        "all_split_edges = drug_disease_edges[drug_disease_edges[\"x_index\"].isin(disease_splits_filtered[\"node_index\"].unique())]\n",
        "all_split_edges.to_csv(split_dir / \"all.csv\", index=False, encoding=\"utf-8-sig\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
